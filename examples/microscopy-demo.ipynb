{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/talmolab/dreem/blob/docs/examples/microscopy-demo-simple.ipynb)\n",
    "\n",
    "## DREEM workflow for microscopy\n",
    "### From raw tiff stacks to tracked identities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will walk you through the typical workflow for microscopy identity tracking. We start with a raw tiff stack, pass it through an off-the-shelf detection model, and feed those detections into DREEM. \n",
    "\n",
    "This notebook uses a simple entrypoint into the tracking code. You only need to specify a configuration file, and a few lines of code!\n",
    "\n",
    "To run this demo, we have provided sample data and model checkpoints. A GPU is recommended if you run the CellPose segmentation step, otherwise the tracking will run on a CPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install DREEM \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!uv pip install dreem-track cellpose tifffile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import sleap_io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from huggingface_hub import hf_hub_download\n",
    "from dreem.utils import run_cellpose_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_dir = \"./models\"\n",
    "os.makedirs(model_save_dir, exist_ok=True)\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"talmolab/microscopy-pretrained\",\n",
    "    filename=\"pretrained-microscopy.ckpt\",\n",
    "    local_dir=model_save_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "### Option 1: Upload Your Own Data\n",
    "\n",
    "Upload your files directly using the **Colab file browser**: click the folder icon in the left sidebar, navigate into `./data/`, and drag and drop your files in.\n",
    "\n",
    "- **TIFF directory**: Upload the individual TIFF frame files into `./data/<your_folder_name>/<video_name>`. For example, `./data/organelles/lysosomes-1`.\n",
    "- **Video** (`.avi`, `.mp4`): Upload the video file to `./data/`, then run the conversion cell below\n",
    "\n",
    "> If you do not have your own data, skip ahead to **Option 2** to download our sample dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert a video to TIFF frames. Skip this cell if you uploaded a TIFF directory.\n",
    "\n",
    "If you uploaded a `.avi` or `.mp4` file, set `video_path` below and run the cell to convert it to individual TIFF frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = \"./data/your_video.mp4\"  # <-- update this to your uploaded file\n",
    "\n",
    "base_name = os.path.splitext(os.path.basename(video_path))[0]\n",
    "custom_data_path = f\"./data/{base_name}/{base_name}\"\n",
    "custom_segmented_path = f\"./data/{base_name}/{base_name}_GT/TRA\"\n",
    "os.makedirs(custom_data_path, exist_ok=True)\n",
    "os.makedirs(custom_segmented_path, exist_ok=True)\n",
    "\n",
    "video = sio.load_video(video_path)\n",
    "for i, frame in enumerate(video):\n",
    "    frame = frame[..., 0] if frame.ndim == 3 else frame\n",
    "    with tifffile.TiffWriter(\n",
    "        os.path.join(custom_data_path, f\"frame_{i:05}.tif\"), mode=\"w\"\n",
    "    ) as writer:\n",
    "        writer.write(frame)\n",
    "\n",
    "print(f\"Done. TIFF stack saved to: {custom_data_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Use Sample Data\n",
    "\n",
    "If you don't have your own data, run the cell below to download our sample microscopy dataset from HuggingFace. The download includes:\n",
    "\n",
    "- **DynamicNuclearNet** â€” cell nuclei imaged with fluorescence microscopy. A single tiff stack of 42 frames. Data credit to Van Valen Lab (https://doi.org/10.1101/803205)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hf download talmolab/microscopy-demo --repo-type dataset --local-dir ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection\n",
    "\n",
    "Here we use CellPose to create segmentation masks for our instances.\n",
    "\n",
    "Update the path below to the path to the directory containing the tiff files. If you are using our sample data, the path is already set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/dynamicnuclearnet/test_1\" # <-- update this to the path to the directory containing the tiff files\n",
    "\n",
    "segmented_path = f\"{data_path}_GT/TRA\"\n",
    "os.makedirs(segmented_path, exist_ok=True)\n",
    "base_name = os.path.dirname(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the approximate diameter (in pixels) of the instances you want to segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_diameter_px = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_flag = \"--gpu\" if torch.cuda.is_available() else \"--no-gpu\"\n",
    "\n",
    "# runs Cellpose and outputs files to segmented_path\n",
    "masks = run_cellpose_segmentation(\n",
    "    data_path,\n",
    "    segmented_path,\n",
    "    diameter=instance_diameter_px,\n",
    "    gpu=gpu_flag,\n",
    ")\n",
    "# Load the original stack and masks for visualization\n",
    "tiff_files = [\n",
    "    f for f in os.listdir(data_path) if f.endswith(\".tif\") or f.endswith(\".tiff\")\n",
    "]\n",
    "tiff_files.sort()  # Ensure consistent ordering\n",
    "first_img = tifffile.imread(os.path.join(data_path, tiff_files[0]))\n",
    "mask_path = os.path.join(segmented_path, f\"{os.path.splitext(tiff_files[0])[0]}.tif\")\n",
    "first_mask = tifffile.imread(mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the segmentation result and original image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax1.imshow(first_mask)\n",
    "ax1.set_title(\"Segmentation Mask\")\n",
    "ax2.imshow(first_img)\n",
    "ax2.set_title(\"Original Image\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking\n",
    "\n",
    "This assumes you have the run the CellPose segmentation step. The output is a single tiff file with all frames, as well as configurations used for tracking (this will help reproduce results). The location is what you set below with the --output flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dreem track {base_name} --checkpoint ./models/pretrained-microscopy.ckpt --output ./results --video-type tif --crop-size {instance_diameter_px}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the results\n",
    "To visualize the tracked tiff stacks, you can use tools like ImageJ, Fiji, or Napari plugins."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
