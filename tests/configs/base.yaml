model:
  ckpt_path: null
  encoder_model: "resnet18"
  encoder_cfg: {}
  d_model: 512
  nhead: 8
  num_encoder_layers: 1
  num_decoder_layers: 1
  dim_feedforward: 512
  dropout: 0.1
  activation: "relu"
  return_intermediate_dec: False
  feature_dim_attn_head: 512
  norm: False
  num_layers_attn_head: 2
  dropout_attn_head: 0.1
  embedding_meta: 
    embedding_type: 'learned_pos_temp'
    kwargs: 
      learn_pos_emb_num: 16
      learn_temp_emb_num: 16
      over_boxes: False
  return_embedding: False
  decoder_self_attn: False

loss:
  neg_unmatched: false
  epsilon: 1e-4
  asso_weight: 1.0

#currently assumes adam. TODO adapt logic for other optimizers like sgd
optimizer:
  name: "Adam"
  lr: 0.001
  betas: [0.9, 0.999]
  eps: 1e-8
  weight_decay: 0.01

#currently assumes reduce lr on plateau
scheduler:
  name: "ReduceLROnPlateau"
  mode: "min"
  factor: 0.5
  patience: 10
  threshold: 1e-4
  threshold_mode: "rel"
  
tracker:
  window_size: 8
  use_vis_feats: true
  overlap_thresh: 0.01
  mult_thresh: true
  decay_time: null
  iou: null
  max_center_dist: null

runner:
  train_metrics: [""]
  val_metrics: ["sw_cnt"]
  test_metrics: ["sw_cnt"]

dataset:
  train_dataset:
    slp_files: ['tests/data/sleap/two_flies.slp']
    video_files: ['tests/data/sleap/two_flies.mp4']
    padding: 5
    crop_size: 128
    chunk: true
    clip_length: 4
    crop_type: 'centroid'

  val_dataset:
    slp_files: ['tests/data/sleap/two_flies.slp']
    video_files: ['tests/data/sleap/two_flies.mp4']
    padding: 5
    crop_size: 128 
    chunk: True
    clip_length: 8
    crop_type: 'centroid'

  test_dataset:
    slp_files: ['tests/data/sleap/two_flies.slp']
    video_files: ['tests/data/sleap/two_flies.mp4']
    padding: 5
    crop_size: 128 
    chunk: True
    clip_length: 16
    crop_type: 'centroid'

dataloader:
  train_dataloader:
    shuffle: true
    num_workers: 0
  val_dataloader:
    shuffle: false
    num_workers: 0
  test_dataloader: 
    shuffle: false
    num_workers: 0

logging:
  name: "example_train"
  entity: null
  job_type: "train"
  notes: "Example train job"
  dir: "./logs"
  group: "example"
  save_dir: './logs'
  project: "GTR"
  log_model: "all"

early_stopping:
  monitor: "val_loss"
  min_delta: 0.1
  patience: 10
  mode: "min"
  check_finite: true
  stopping_threshold: 1e-8
  divergence_threshold: 30

checkpointing:
  monitor: ["val_loss","val_sw_cnt"]
  verbose: true
  save_last: true
  dirpath: null
  auto_insert_metric_name: true
  every_n_epochs: 10

trainer:
  check_val_every_n_epoch: 1
  enable_checkpointing: true
  gradient_clip_val: null
  limit_train_batches: 1.0
  limit_test_batches: 1.0
  limit_val_batches: 1.0
  log_every_n_steps: 1
  max_epochs: 100
  min_epochs: 10





