# DREEM Relates Every Entity's Motion

[![CI](https://github.com/talmolab/dreem/actions/workflows/ci.yml/badge.svg)](https://github.com/talmolab/dreem/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/talmolab/dreem/branch/main/graph/badge.svg?token=Sj8kIFl3pi)](https://codecov.io/gh/talmolab/dreem)
[![code](https://img.shields.io/github/stars/talmolab/dreem)](https://github.com/talmolab/dreem)
<!-- [![Release](https://img.shields.io/github/v/release/talmolab/dreem?label=Latest)](https://github.com/talmolab/dreem/releases/)
[![PyPI](https://img.shields.io/pypi/v/dreem-tracker?label=PyPI)](https://pypi.org/project/dreem-tracker)
![PyPI - Python Version](https://img.shields.io/pypi/pyversions/dreem-tracker) -->


Welcome to the documentation for **DREEM** â€“ an open-source tool for multiple object tracking. DREEM is a framework that enables you to train your own models, run inference on new data, and evaluate your results. DREEM supports a variety of detection types, including keypoints, bounding boxes, and segmentation masks. You can use any detection model you want, convert the output to a format DREEM can use, and train a model or run inference using a pretrained model.



## Key Features

- **Command-Line & API Access:** Use DREEM via a simple CLI or integrate into your own Python scripts.
- **Configurable Workflows:** Easily customize training and inference using YAML configuration files.
- **Pretrained Models:** Get started quickly with models trained specially for microscopy and animal domains.
- **Visualization:** Tracking outputs are directly compatible with SLEAP's GUI.
- **Examples:** Step-by-step notebooks and guides for common workflows.


## Installation

Head over to the [Installation Guide](./installation.md) to get started.


## Quickstart

Ready to try DREEM? Follow the [Quickstart Guide](./quickstart.md) to:

1. Download example datasets and pretrained models
2. Run tracking on sample videos
3. Visualize your results


## Example Workflows

Explore the Examples section for notebooks that walk you through the DREEM pipeline. We have an end-to-end demo that includes model training, as well as a microscopy example that shows how to use DREEM with an off-the-shelf detection model.


## Documentation Structure

- [Installation](./installation.md)
- [Quickstart](./quickstart.md)
- [Usage Guide](./usage.md)
- Examples
- [API Reference](https://dreem.sleap.ai/reference/dreem/)

## Get Help

- **Questions?** Open an issue on [GitHub](https://github.com/talmolab/dreem/issues).
- **Contributions:** We welcome contributions! See our [Contributing Guide](#) for details (link to be added).


<!-- ## Citing DREEM

If you use DREEM in your research, please cite our [paper](#) (link to be added). -->